abline(lm(y ~ x), col='green')
mean(y)
histogram(y)
hist(y)
dev.off()
x = unlist(rowMeans(marcel_gpt_adjust[,c(1,2,3)]))
y = unlist(marcel_gpt_adjust[,4])
dev.off()
plot(x,y,col='red')
correlation <- cor(x,y)
abline(lm(y ~ x), col='green')
hist(y)
y = unlist(marcel_phy_adjust[,4])
hist(y)
rm(list=ls())
setwd('/Users/burcutepekule/Library/CloudStorage/Dropbox/criticalwindow/code/R/RStan')
library("bayesplot")
library("ggplot2")
library("rstanarm")
library('rstan')
library('brms')
library('dplyr')
# https://cran.r-project.org/web/packages/rstan/vignettes/stanfit-objects.html
pathModelOutput='/Users/burcutepekule/Library/CloudStorage/Dropbox/criticalwindow/code/R/RStan/OUT/17062023/RDATA';
fileList = list.files(path =pathModelOutput, pattern='.RData')
##### Pick the file
indexPick     = 1
fileNamePick  = paste0(pathModelOutput,"/",fileList[indexPick])
#################################################
### load the model object - clean up afterwards
temp.space <- new.env()
bar <- load(fileNamePick, temp.space)
loadedModel <- get(bar, temp.space)
rm(temp.space)
fit           = loadedModel
fitSummary    = summary(fit)
fileNamePick
rm(list=ls())
setwd('/Users/burcutepekule/Library/CloudStorage/Dropbox/criticalwindow/code/R/RStan')
library("bayesplot")
library("ggplot2")
library("rstanarm")
library('rstan')
library('brms')
library('dplyr')
# https://cran.r-project.org/web/packages/rstan/vignettes/stanfit-objects.html
pathModelOutput='/Users/burcutepekule/Library/CloudStorage/Dropbox/criticalwindow/code/R/RStan/OUT/17062023/RDATA';
fileList = list.files(path =pathModelOutput, pattern='.RData')
##### Pick the file
indexPick     = 1
fileNamePick  = paste0(pathModelOutput,"/",fileList[indexPick])
#################################################
### load the model object - clean up afterwards
temp.space <- new.env()
bar <- load(fileNamePick, temp.space)
loadedModel <- get(bar, temp.space)
rm(temp.space)
#################################################
fit           = loadedModel
fitSummary    = summary(fit)
posterior     = as.array(fit)
list_of_draws = rstan::extract(loadedModel)
paramRoot     = as.name('interactionMat_vector_diag')
numOfParams   = dim(list_of_draws[[paramRoot]])[2]
n_chains <- fit@sim$chains
n_warmup <- fit@sim$warmup2[1]
n_iter   <-fit@sim$iter[[1]]
print(c(n_iter,n_warmup,n_chains))
paramNames=c()
for(i in 1:numOfParams){
paramNames = c(paramNames,paste0(paramRoot,'[',i,']'))
}
# color_scheme_set("brightblue")
# mcmc_dens(posterior, pars = paramNames,
#           facet_args = list(ncol = 1, strip.position = "left"))
#
# color_scheme_set("brightblue")
# mcmc_intervals(posterior, pars = paramNames)
#
# color_scheme_set("viridis")
# mcmc_trace(posterior, pars = paramNames,
#            facet_args = list(ncol = 1, strip.position = "left"))
#################################################
source("SETUP.R")
source('RESHAPE_DATA_KNIGHT.R')
taxa_array = colnames(abundanceArray_meanSubjects)
# compartment_names = 'output_pred'
# summaryTable = as.data.frame(summary(loadedModel,compartment_names)[[1]])
# summaryTable$populationNames = rownames(summaryTable)
# summaryTable$t    = sub(",.*","",sub(".*\\[", "", summaryTable$populationNames))  # Extract characters after pattern
# summaryTable$taxa = sub("\\].*","",sub(".*,", "", summaryTable$populationNames))  # Extract characters after pattern
# summaryTable_use = summaryTable[c('t','taxa','mean','2.5%','97.5%','50%')]
# summaryTable_use$t = as.numeric(summaryTable_use$t)
# summaryTable_use$mean = as.numeric(summaryTable_use$mean)
# summaryTable_use$`97.5%` = as.numeric(summaryTable_use$`97.5%`)
# summaryTable_use$`2.5%` = as.numeric(summaryTable_use$`2.5%`)
# summaryTable_use$`50%` = as.numeric(summaryTable_use$`50%`)
# summaryTable_use$taxa = paste0('y_',summaryTable_use$taxa)
# summaryTable_use = summaryTable_use %>% rowwise() %>% mutate(taxa = taxa_array[as.numeric(sub(",.*","",sub(".*\\_", "", taxa)))] )
#
# graphics.off()
# ggplot() +
#   geom_point(data=abundanceArray_meanSubjects_longer,aes(x=day,y=abundance,fill=taxa),shape=21,size=1,colour = "black", fill = "white") +
#   # geom_ribbon(data=summaryTable_use,aes(x=t,ymin=`2.5%`,ymax=`97.5%`,fill=taxa),alpha=.5) +
#   geom_line(data=summaryTable_use,aes(x=t,y=`50%`),colour="black") +
#   facet_wrap(~ taxa ,scales="free",nrow=2) +
#   scale_colour_manual(values=c("grey20","grey"),guide=FALSE) +
#   scale_alpha_manual(values=c(1,0),guide=FALSE) +
#   # scale_y_continuous(trans = 'log10')+
#   labs(x="sample index",y="abundance")
# graphics.off()
# ggplot(summaryTable_use, aes(x = t, y = mean, color = taxa)) + geom_point()
# Save the interaction matricies to compare
paramRoot     = as.name('interactionMat_vector_diag')
numOfParams   = dim(list_of_draws[[paramRoot]])[2]
paramNames_diag=c()
for(i in 1:numOfParams){
paramNames_diag = c(paramNames_diag,paste0(paramRoot,'[',i,']'))
}
paramRoot     = as.name('interactionMat_vector_nondiag')
numOfParams   = dim(list_of_draws[[paramRoot]])[2]
paramNames_nondiag=c()
for(i in 1:numOfParams){
paramNames_nondiag = c(paramNames_nondiag,paste0(paramRoot,'[',i,']'))
}
paramRoot     = as.name('growthRate_vector')
numOfParams   = dim(list_of_draws[[paramRoot]])[2]
paramNames_growth=c()
for(i in 1:numOfParams){
paramNames_growth = c(paramNames_growth,paste0(paramRoot,'[',i,']'))
}
summaryTable_nondiag = as.data.frame(summary(loadedModel,paramNames_nondiag)[[1]])
summaryTable_diag    = as.data.frame(summary(loadedModel,paramNames_diag)[[1]])
summaryTable_growth  = as.data.frame(summary(loadedModel,paramNames_growth)[[1]])
# https://mc-stan.org/rstan/reference/Rhat.html
# my Rhats are terrible...
############ INTERACTION MATRIX
interactionMatrix      = matrix(0,nrow = length(taxa_array), ncol = length(taxa_array))
interactionMatrix_rhat = matrix(0,nrow = length(taxa_array), ncol = length(taxa_array))
names_diag    = rownames(summaryTable_diag)
names_nondiag = rownames(summaryTable_nondiag)
idx_diag      = as.numeric(sub("\\].*", "",sub(".*\\[", "", names_diag)))
idx_nondiag   = as.numeric(sub("\\].*", "",sub(".*\\[", "", names_nondiag)))
numCols       = length(taxa_array)
correctIndex  = 0
for (r in 1:length(taxa_array)){
for (c in 1:length(taxa_array)){
if(r==c){
interactionMatrix[r,c]      = -1*summaryTable_diag[which(idx_diag==r),]$mean
interactionMatrix_rhat[r,c] = summaryTable_diag[which(idx_diag==r),]$Rhat
correctIndex = correctIndex + 1
}else{
idx_nondiag_corrected       = idx_nondiag+correctIndex
interactionMatrix[r,c]      = summaryTable_nondiag[which(idx_nondiag_corrected==((r-1)*numCols) + c),]$mean
interactionMatrix_rhat[r,c] = summaryTable_nondiag[which(idx_nondiag_corrected==((r-1)*numCols) + c),]$Rhat
}
}
}
colnames(interactionMatrix) = taxa_array
rownames(interactionMatrix) = taxa_array
colnames(interactionMatrix_rhat) = taxa_array
rownames(interactionMatrix_rhat) = taxa_array
library(openxlsx)
ts = as.numeric(sub(".*\\_", "",sub("\\.RData.*", "",fileList[indexPick])))
wb <- createWorkbook()
addWorksheet(wb, "mean")
addWorksheet(wb, "Rhat")
writeData(wb, "mean", as.data.frame(interactionMatrix), startRow = 1, startCol = 1)
writeData(wb, "Rhat", as.data.frame(interactionMatrix_rhat), startRow = 1, startCol = 1)
saveWorkbook(wb, file = paste0(pathModelOutput,"/INTERACTIONS_",ts,".xlsx"), overwrite = TRUE)
############ GROWTH
growthMatrix      = matrix(0,nrow = 1, ncol = length(taxa_array))
growthMatrix_rhat = matrix(0,nrow = 1, ncol = length(taxa_array))
names_growth = rownames(summaryTable_growth)
idx_growth   = as.numeric(sub("\\].*", "",sub(".*\\[", "", names_growth)))
for (c in 1:length(taxa_array)){
growthMatrix[1,c]      = summaryTable_growth[which(idx_growth==c),]$mean
growthMatrix_rhat[1,c] = summaryTable_growth[which(idx_growth==c),]$Rhat
}
colnames(growthMatrix) = taxa_array
colnames(growthMatrix_rhat) = taxa_array
library(openxlsx)
ts = as.numeric(sub(".*\\_", "",sub("\\.RData.*", "",fileList[indexPick])))
wb <- createWorkbook()
addWorksheet(wb, "mean")
addWorksheet(wb, "Rhat")
writeData(wb, "mean", as.data.frame(growthMatrix), startRow = 1, startCol = 1)
writeData(wb, "Rhat", as.data.frame(growthMatrix_rhat), startRow = 1, startCol = 1)
saveWorkbook(wb, file = paste0(pathModelOutput,"/GROWTH_",ts,".xlsx"), overwrite = TRUE)
compartment_names = 'output_pred'
summaryTable = as.data.frame(summary(loadedModel,compartment_names)[[1]])
summaryTable$populationNames = rownames(summaryTable)
summaryTable$t    = sub(",.*","",sub(".*\\[", "", summaryTable$populationNames))  # Extract characters after pattern
summaryTable$taxa = sub("\\].*","",sub(".*,", "", summaryTable$populationNames))  # Extract characters after pattern
summaryTable_use = summaryTable[c('t','taxa','mean','2.5%','97.5%','50%')]
summaryTable_use$t = as.numeric(summaryTable_use$t)
summaryTable_use$mean = as.numeric(summaryTable_use$mean)
summaryTable_use$`97.5%` = as.numeric(summaryTable_use$`97.5%`)
summaryTable_use$`2.5%` = as.numeric(summaryTable_use$`2.5%`)
summaryTable_use$`50%` = as.numeric(summaryTable_use$`50%`)
summaryTable_use$taxa = paste0('y_',summaryTable_use$taxa)
summaryTable_use = summaryTable_use %>% rowwise() %>% mutate(taxa = taxa_array[as.numeric(sub(",.*","",sub(".*\\_", "", taxa)))] )
graphics.off()
ggplot() +
geom_point(data=abundanceArray_meanSubjects_longer,aes(x=day,y=abundance,fill=taxa),shape=21,size=1,colour = "black", fill = "white") +
# geom_ribbon(data=summaryTable_use,aes(x=t,ymin=`2.5%`,ymax=`97.5%`,fill=taxa),alpha=.5) +
geom_line(data=summaryTable_use,aes(x=t,y=`50%`),colour="black") +
facet_wrap(~ taxa ,scales="free",nrow=2) +
scale_colour_manual(values=c("grey20","grey"),guide=FALSE) +
scale_alpha_manual(values=c(1,0),guide=FALSE) +
# scale_y_continuous(trans = 'log10')+
labs(x="sample index",y="abundance")
graphics.off()
ggplot() +
geom_point(data=abundanceArray_meanSubjects_longer,aes(x=day,y=abundance,fill=taxa),shape=21,size=1,colour = "black", fill = "white") +
# geom_ribbon(data=summaryTable_use,aes(x=t,ymin=`2.5%`,ymax=`97.5%`,fill=taxa),alpha=.5) +
geom_line(data=summaryTable_use,aes(x=t,y=`50%`),colour="black") +
facet_wrap(~ taxa ,scales="free",nrow=2) +
scale_colour_manual(values=c("grey20","grey")) +
scale_alpha_manual(values=c(1,0)) +
# scale_y_continuous(trans = 'log10')+
labs(x="sample index",y="abundance")
color_scheme_set("brightblue")
mcmc_intervals(posterior, pars = paramNames)
color_scheme_set("viridis")
mcmc_trace(posterior, pars = paramNames,
facet_args = list(ncol = 1, strip.position = "left"))
color_scheme_set("brightblue")
mcmc_dens(posterior, pars = paramNames,
facet_args = list(ncol = 1, strip.position = "left"))
#!/usr/bin/env Rscript
args = commandArgs(trailingOnly=TRUE)
# setwd(getwd())
setwd('/Users/burcutepekule/Library/CloudStorage/Dropbox/criticalwindow/code/R/RStan')
source("SETUP.R")
source('RESHAPE_DATA_KNIGHT.R')
# test if there is at least one argument: if not, return an error
if (length(args)==0) {
stop("At least one argument must be supplied (input file).n", call.=FALSE)
} else if (length(args)>0) {
# default output file
df_config = read.table(args[1], header=TRUE)
}
df_config     = read.table('config_raw.txt', header = TRUE, sep = "", dec = ".")
# setwd(getwd())
setwd('/Users/burcutepekule/Library/CloudStorage/Dropbox/criticalwindow/code/R/RStan')
source("SETUP.R")
source('RESHAPE_DATA_KNIGHT.R')
#!/usr/bin/env Rscript
# args = commandArgs(trailingOnly=TRUE)
setwd('/Users/burcutepekule/Library/CloudStorage/Dropbox/criticalwindow/code/R/RStan')
source("SETUP.R")
source('RESHAPE_DATA_KNIGHT.R')
# # test if there is at least one argument: if not, return an error
# if (length(args)==0) {
#   stop("At least one argument must be supplied (input file).n", call.=FALSE)
# } else if (length(args)>0) {
#   # default output file
#   df_config = read.table(args[1], header=TRUE)
# }
df_config     = read.table('config_raw.txt', header = TRUE, sep = "", dec = ".")
scale         = df_config[which(df_config[,1]=='scale'),2]
smoothed      = df_config[which(df_config[,1]=='smoothed'),2]
numWarmup     = df_config[which(df_config[,1]=='numWarmup'),2]
numIterations = df_config[which(df_config[,1]=='numIterations'),2]
numChains     = df_config[which(df_config[,1]=='numChains'),2]
valSeed       = df_config[which(df_config[,1]=='valSeed'),2]
odeSolver     = df_config[which(df_config[,1]=='odeSolver'),2]
# HUMAN MICROBIOME PROJECT DATA
# y0_meanSubjects
# abundanceArray_meanSubjects
# data_knight_M5_t, day_grid_M5
# data_knight_F5_t, day_grid_F5
## scale up
# scale = 1E11 # TOO BIG
# scale = 0 # DOABLE
if(scale>0){
y0_meanSubjects             = round(scale*y0_meanSubjects)
names(y0_meanSubjects)      = colnames(abundanceArray_meanSubjects)
days_array = as.numeric(rownames(abundanceArray_meanSubjects))
taxa_array = colnames(abundanceArray_meanSubjects)
abundanceArray_meanSubjects = as.data.frame(lapply(abundanceArray_meanSubjects, function(x) as.numeric(x))) #normalize and scale to absolute abundance
abundanceArray_meanSubjects = as.data.frame(lapply(abundanceArray_meanSubjects, function(x) as.integer(round(scale*x)))) #normalize and scale to absolute abundance
abundanceArray_meanSubjects_longer$abundance = as.integer(round(scale*abundanceArray_meanSubjects_longer$abundance)) #normalize and scale to absolute abundance
phi_use_exp                 = max(round(log10(y0_meanSubjects)));
phi_use                     = 10^(phi_use_exp+0) # SEEMS LIKE 1E6 IS THE ONE THAT WORKS, SO NEED TO GET THIS FROM THE ORDER OF MAG. OF THE DATA
}else{
names(y0_meanSubjects)      = colnames(abundanceArray_meanSubjects)
days_array = as.numeric(rownames(abundanceArray_meanSubjects))
taxa_array = colnames(abundanceArray_meanSubjects)
abundanceArray_meanSubjects = as.data.frame(lapply(abundanceArray_meanSubjects, function(x) as.numeric(x))) #normalize and scale to absolute abundance
phi_use_exp                 = max((log10(y0_meanSubjects)));
phi_use                     = 10^(phi_use_exp+0) # SEEMS LIKE 1E6 IS THE ONE THAT WORKS, SO NEED TO GET THIS FROM THE ORDER OF MAG. OF THE DATA
}
indexes = 1:9 # ALL
abundanceArray_meanSubjects = abundanceArray_meanSubjects[,indexes]
y0_meanSubjects             = y0_meanSubjects[indexes]
taxa_array                  = taxa_array[indexes]
abundanceArray_meanSubjects_longer = abundanceArray_meanSubjects_longer %>% filter(taxa %in% taxa_array)
# maybe smooth before use?
if(smoothed==1){
abundanceArray_meanSubjects_keep = abundanceArray_meanSubjects
for (c in 1:dim(abundanceArray_meanSubjects)[2]){
tempcolumn  = abundanceArray_meanSubjects_keep[,c]
dayvector   = days_array
taxa_model  = loess(tempcolumn ~ days_array,  family = c("gaussian"), span=7)
smooth_data = predict(taxa_model, data.frame(day = days_array), se = TRUE)
# plot(smooth_data$fit)
abundanceArray_meanSubjects[,c]=unlist(smooth_data$fit)
}
}
taxa_array
rm(list=ls())
setwd('/Users/burcutepekule/Library/CloudStorage/Dropbox/criticalwindow/code/R/RStan')
library("bayesplot")
library("ggplot2")
library("rstanarm")
library('rstan')
library('brms')
library('dplyr')
# https://cran.r-project.org/web/packages/rstan/vignettes/stanfit-objects.html
pathModelOutput='/Users/burcutepekule/Library/CloudStorage/Dropbox/criticalwindow/code/R/RStan/OUT/17062023/RDATA';
fileList = list.files(path =pathModelOutput, pattern='.RData')
##### Pick the file
indexPick     = 1
fileNamePick  = paste0(pathModelOutput,"/",fileList[indexPick])
#################################################
### load the model object - clean up afterwards
temp.space <- new.env()
bar <- load(fileNamePick, temp.space)
loadedModel <- get(bar, temp.space)
rm(temp.space)
#################################################
fit           = loadedModel
fitSummary    = summary(fit)
posterior     = as.array(fit)
list_of_draws = rstan::extract(loadedModel)
paramRoot     = as.name('interactionMat_vector_diag')
numOfParams   = dim(list_of_draws[[paramRoot]])[2]
n_chains <- fit@sim$chains
n_warmup <- fit@sim$warmup2[1]
n_iter   <-fit@sim$iter[[1]]
print(c(n_iter,n_warmup,n_chains))
paramNames=c()
for(i in 1:numOfParams){
paramNames = c(paramNames,paste0(paramRoot,'[',i,']'))
}
color_scheme_set("brightblue")
mcmc_dens(posterior, pars = paramNames,
facet_args = list(ncol = 1, strip.position = "left"))
color_scheme_set("brightblue")
mcmc_intervals(posterior, pars = paramNames)
color_scheme_set("viridis")
mcmc_trace(posterior, pars = paramNames,
facet_args = list(ncol = 1, strip.position = "left"))
#################################################
source("SETUP.R")
source('RESHAPE_DATA_KNIGHT.R')
taxa_array = colnames(abundanceArray_meanSubjects)
compartment_names = 'output_pred'
summaryTable = as.data.frame(summary(loadedModel,compartment_names)[[1]])
summaryTable$populationNames = rownames(summaryTable)
summaryTable$t    = sub(",.*","",sub(".*\\[", "", summaryTable$populationNames))  # Extract characters after pattern
summaryTable$taxa = sub("\\].*","",sub(".*,", "", summaryTable$populationNames))  # Extract characters after pattern
summaryTable_use = summaryTable[c('t','taxa','mean','2.5%','97.5%','50%')]
summaryTable_use$t = as.numeric(summaryTable_use$t)
summaryTable_use$mean = as.numeric(summaryTable_use$mean)
summaryTable_use$`97.5%` = as.numeric(summaryTable_use$`97.5%`)
summaryTable_use$`2.5%` = as.numeric(summaryTable_use$`2.5%`)
summaryTable_use$`50%` = as.numeric(summaryTable_use$`50%`)
summaryTable_use$taxa = paste0('y_',summaryTable_use$taxa)
summaryTable_use = summaryTable_use %>% rowwise() %>% mutate(taxa = taxa_array[as.numeric(sub(",.*","",sub(".*\\_", "", taxa)))] )
graphics.off()
ggplot() +
geom_point(data=abundanceArray_meanSubjects_longer,aes(x=day,y=abundance,fill=taxa),shape=21,size=1,colour = "black", fill = "white") +
# geom_ribbon(data=summaryTable_use,aes(x=t,ymin=`2.5%`,ymax=`97.5%`,fill=taxa),alpha=.5) +
geom_line(data=summaryTable_use,aes(x=t,y=`50%`),colour="black") +
facet_wrap(~ taxa ,scales="free",nrow=2) +
scale_colour_manual(values=c("grey20","grey")) +
scale_alpha_manual(values=c(1,0)) +
# scale_y_continuous(trans = 'log10')+
labs(x="sample index",y="abundance")
# graphics.off()
# ggplot(summaryTable_use, aes(x = t, y = mean, color = taxa)) + geom_point()
# Save the interaction matricies to compare
paramRoot     = as.name('interactionMat_vector_diag')
numOfParams   = dim(list_of_draws[[paramRoot]])[2]
paramNames_diag=c()
for(i in 1:numOfParams){
paramNames_diag = c(paramNames_diag,paste0(paramRoot,'[',i,']'))
}
paramRoot     = as.name('interactionMat_vector_nondiag')
numOfParams   = dim(list_of_draws[[paramRoot]])[2]
paramNames_nondiag=c()
for(i in 1:numOfParams){
paramNames_nondiag = c(paramNames_nondiag,paste0(paramRoot,'[',i,']'))
}
paramRoot     = as.name('growthRate_vector')
numOfParams   = dim(list_of_draws[[paramRoot]])[2]
paramNames_growth=c()
for(i in 1:numOfParams){
paramNames_growth = c(paramNames_growth,paste0(paramRoot,'[',i,']'))
}
summaryTable_nondiag = as.data.frame(summary(loadedModel,paramNames_nondiag)[[1]])
summaryTable_nondiag = as.data.frame(summary(loadedModel,paramNames_nondiag)[[1]])
summaryTable_nondiag = as.data.frame(summary(loadedModel,paramNames_nondiag)[[1]])
summaryTable_diag    = as.data.frame(summary(loadedModel,paramNames_diag)[[1]])
summaryTable_growth  = as.data.frame(summary(loadedModel,paramNames_growth)[[1]])
View(summaryTable_growth)
View(summaryTable_diag)
taxa_array
setwd('/Users/burcutepekule/Library/CloudStorage/Dropbox/criticalwindow/code/R/RStan')
source("SETUP.R")
source('RESHAPE_DATA_KNIGHT.R')
df_config     = read.table('config_raw.txt', header = TRUE, sep = "", dec = ".")
#!/usr/bin/env Rscript
# args = commandArgs(trailingOnly=TRUE)
setwd('/Users/burcutepekule/Library/CloudStorage/Dropbox/criticalwindow/code/R/RStan')
source("SETUP.R")
source('RESHAPE_DATA_KNIGHT.R')
# # test if there is at least one argument: if not, return an error
# if (length(args)==0) {
#   stop("At least one argument must be supplied (input file).n", call.=FALSE)
# } else if (length(args)>0) {
#   # default output file
#   df_config = read.table(args[1], header=TRUE)
# }
df_config     = read.table('config_raw.txt', header = TRUE, sep = "", dec = ".")
scale         = df_config[which(df_config[,1]=='scale'),2]
smoothed      = df_config[which(df_config[,1]=='smoothed'),2]
numWarmup     = df_config[which(df_config[,1]=='numWarmup'),2]
numIterations = df_config[which(df_config[,1]=='numIterations'),2]
numChains     = df_config[which(df_config[,1]=='numChains'),2]
valSeed       = df_config[which(df_config[,1]=='valSeed'),2]
odeSolver     = df_config[which(df_config[,1]=='odeSolver'),2]
# HUMAN MICROBIOME PROJECT DATA
# y0_meanSubjects
# abundanceArray_meanSubjects
# data_knight_M5_t, day_grid_M5
# data_knight_F5_t, day_grid_F5
## scale up
# scale = 1E11 # TOO BIG
# scale = 0 # DOABLE
if(scale>0){
y0_meanSubjects             = round(scale*y0_meanSubjects)
names(y0_meanSubjects)      = colnames(abundanceArray_meanSubjects)
days_array = as.numeric(rownames(abundanceArray_meanSubjects))
taxa_array = colnames(abundanceArray_meanSubjects)
abundanceArray_meanSubjects = as.data.frame(lapply(abundanceArray_meanSubjects, function(x) as.numeric(x))) #normalize and scale to absolute abundance
abundanceArray_meanSubjects = as.data.frame(lapply(abundanceArray_meanSubjects, function(x) as.integer(round(scale*x)))) #normalize and scale to absolute abundance
abundanceArray_meanSubjects_longer$abundance = as.integer(round(scale*abundanceArray_meanSubjects_longer$abundance)) #normalize and scale to absolute abundance
phi_use_exp                 = max(round(log10(y0_meanSubjects)));
phi_use                     = 10^(phi_use_exp+0) # SEEMS LIKE 1E6 IS THE ONE THAT WORKS, SO NEED TO GET THIS FROM THE ORDER OF MAG. OF THE DATA
}else{
names(y0_meanSubjects)      = colnames(abundanceArray_meanSubjects)
days_array = as.numeric(rownames(abundanceArray_meanSubjects))
taxa_array = colnames(abundanceArray_meanSubjects)
abundanceArray_meanSubjects = as.data.frame(lapply(abundanceArray_meanSubjects, function(x) as.numeric(x))) #normalize and scale to absolute abundance
phi_use_exp                 = max((log10(y0_meanSubjects)));
phi_use                     = 10^(phi_use_exp+0) # SEEMS LIKE 1E6 IS THE ONE THAT WORKS, SO NEED TO GET THIS FROM THE ORDER OF MAG. OF THE DATA
}
indexes = 1:9 # ALL
abundanceArray_meanSubjects = abundanceArray_meanSubjects[,indexes]
y0_meanSubjects             = y0_meanSubjects[indexes]
taxa_array                  = taxa_array[indexes]
abundanceArray_meanSubjects_longer = abundanceArray_meanSubjects_longer %>% filter(taxa %in% taxa_array)
# maybe smooth before use?
if(smoothed==1){
abundanceArray_meanSubjects_keep = abundanceArray_meanSubjects
for (c in 1:dim(abundanceArray_meanSubjects)[2]){
tempcolumn  = abundanceArray_meanSubjects_keep[,c]
dayvector   = days_array
taxa_model  = loess(tempcolumn ~ days_array,  family = c("gaussian"), span=7)
smooth_data = predict(taxa_model, data.frame(day = days_array), se = TRUE)
# plot(smooth_data$fit)
abundanceArray_meanSubjects[,c]=unlist(smooth_data$fit)
}
}
abundanceArray_meanSubjects
colnames(abundanceArray_meanSubjects)
taxa_array
y0_meanSubjects
colnames(y0_meanSubjects)
names(y0_meanSubjects)
taxa_array
## also read the interaction masking matrix
interactionMask = read_excel('KNIGHT_DATA/INTERACTION_MASK.xlsx',col_names = TRUE, skip=1)
View(interactionMask)
## also read the interaction masking matrix
interactionMask = read_excel('KNIGHT_DATA/INTERACTION_MASK.xlsx',col_names = TRUE, skip=0)
View(interactionMask)
unlist(interactionMask)
interactionMask_vector = unlist(interactionMask)
interactionMask_vector
View(interactionMask)
interactionMask_vector = unlist(interactionMask[,2:dim(interactionMask)[2]])
interactionMask_vector
interactionMask_vector = unlist(t(interactionMask[,2:dim(interactionMask)[2]]))
interactionMask_vector
t(interactionMask[,2:dim(interactionMask)[2]])
interactionMask_vector = unlist(t(interactionMask[,2:dim(interactionMask)[2]]))
interactionMask_vector
View(interactionMask)
interactionMask = as.matrix(interactionMask[,2:dim(interactionMask)[2]])
interactionMask
interactionMask_vector = unlist(interactionMask)
interactionMask_vector
interactionMask_vector = as.vector(interactionMask)
interactionMask_vector
interactionMask_vector = as.vector(t(interactionMask))
interactionMask_vector
taxa_array
