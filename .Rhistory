#   paramNames = c(paramNames,paste0(paramRoot,'[',i,']'))
# }
#
# color_scheme_set("brightblue")
# mcmc_dens(posterior, pars = paramNames,
#           facet_args = list(ncol = 1, strip.position = "left"))
#
# color_scheme_set("brightblue")
# mcmc_intervals(posterior, pars = paramNames)
#
# color_scheme_set("viridis")
# mcmc_trace(posterior, pars = paramNames,
#            facet_args = list(ncol = 1, strip.position = "left"))
#################################################
source("SETUP.R")
source('RESHAPE_DATA_KNIGHT_L6.R')
taxa_array = colnames(abundanceArray_meanSubjects)
abundanceArray_meanSubjects_use = abundanceArray_meanSubjects
abundanceArray_meanSubjects_use$day = rownames(abundanceArray_meanSubjects_use)
abundanceArray_meanSubjects_longer = abundanceArray_meanSubjects_use %>% pivot_longer(!day,names_to = 'taxa', values_to = 'abundance')
compartment_names = 'output_pred'
summaryTable = as.data.frame(summary(loadedModel,compartment_names)[[1]])
summaryTable$populationNames = rownames(summaryTable)
summaryTable$t    = sub(",.*","",sub(".*\\[", "", summaryTable$populationNames))  # Extract characters after pattern
summaryTable$taxa = sub("\\].*","",sub(".*,", "", summaryTable$populationNames))  # Extract characters after pattern
summaryTable_use = summaryTable[c('t','taxa','mean','2.5%','97.5%','50%')]
summaryTable_use$t = days_array[as.numeric(summaryTable_use$t)]
summaryTable_use$mean = as.numeric(summaryTable_use$mean)
summaryTable_use$`97.5%` = as.numeric(summaryTable_use$`97.5%`)
summaryTable_use$`2.5%` = as.numeric(summaryTable_use$`2.5%`)
summaryTable_use$`50%` = as.numeric(summaryTable_use$`50%`)
summaryTable_use$taxa = paste0('y_',summaryTable_use$taxa)
summaryTable_use = summaryTable_use %>% rowwise() %>% mutate(taxa = taxa_array[as.numeric(sub(",.*","",sub(".*\\_", "", taxa)))] )
abundanceArray_meanSubjects_longer$type ='stan'
out_longer$type='simulation'
out_longer_day0 = out_longer %>% filter(day==0)
graphics.off()
ggplot() +
geom_point(data=out_longer,aes(x=day,y=abundance,fill=taxa),shape=21,size=1,colour = "red", fill = "white") +
# geom_ribbon(data=summaryTable_use,aes(x=t,ymin=`2.5%`,ymax=`97.5%`,fill=taxa),alpha=.5) +
geom_line(data=summaryTable_use,aes(x=t,y=`50%`),colour="black") +
facet_wrap(~ taxa ,scales="free",nrow=2) +
scale_colour_manual(values=c("grey20","grey")) +
scale_alpha_manual(values=c(1,0)) +
# scale_y_continuous(trans = 'log10')+
labs(x="sample index",y="abundance")
View(out_longer)
graphics.off()
ggplot() +
geom_point(data=out_longer,aes(x=day,y=abundance,fill=taxa),shape=21,size=1,colour = "red", fill = "white") +
geom_ribbon(data=summaryTable_use,aes(x=t,ymin=`2.5%`,ymax=`97.5%`,fill=taxa),alpha=.5) +
geom_line(data=summaryTable_use,aes(x=t,y=`50%`),colour="black") +
facet_wrap(~ taxa ,scales="free",nrow=2) +
scale_colour_manual(values=c("grey20","grey")) +
scale_alpha_manual(values=c(1,0)) +
# scale_y_continuous(trans = 'log10')+
labs(x="sample index",y="abundance")
View(out_longer)
View(summaryTable_use)
rm(list=ls())
setwd('/Users/burcutepekule/Library/CloudStorage/Dropbox/criticalwindow/code/R/RStan')
library("bayesplot")
library("ggplot2")
library("rstanarm")
library('rstan')
library('brms')
library('dplyr')
library(readxl)
library(writexl)
library(deSolve)
# https://cran.r-project.org/web/packages/rstan/vignettes/stanfit-objects.html
source("SETUP.R")
source('RESHAPE_DATA_KNIGHT_L6.R')
taxa_array = colnames(abundanceArray_meanSubjects)
abundanceArray_meanSubjects_use = abundanceArray_meanSubjects
abundanceArray_meanSubjects_use$day = rownames(abundanceArray_meanSubjects_use)
abundanceArray_meanSubjects_longer = abundanceArray_meanSubjects_use %>% pivot_longer(!day,names_to = 'taxa', values_to = 'abundance')
pathModelOutput='/Users/burcutepekule/Library/CloudStorage/Dropbox/criticalwindow/code/R/RStan/OUT/22062023/RDATA';
fileList   = list.files(path =pathModelOutput, pattern='.xlsx')
timestamps = unique(sub("\\.xlsx.*","",sub(".*\\_", "",fileList)))  # Extract characters after pattern
##### Pick the file
indexPick          = 1
timestampPick      = timestamps[indexPick]
growthRateVector   = read_excel(paste0(pathModelOutput,"/GROWTH_",timestampPick,".xlsx"))
interactionMatrix  = read_excel(paste0(pathModelOutput,"/INTERACTIONS_",timestampPick,".xlsx"))
numTaxa            = length(taxa_array)
t_end              = max(as.numeric(unique(abundanceArray_meanSubjects_longer$day)))
source("B1B_ODE_MODEL.R")
#################################################
### load the model object - clean up afterwards
fileNamePick = paste0(pathModelOutput,'/MODEL_SMOOTH_0_ODESOLVER_0_B1B_',timestampPick,'.RData')
temp.space <- new.env()
bar <- load(fileNamePick, temp.space)
loadedModel <- get(bar, temp.space)
rm(temp.space)
#################################################
fit           = loadedModel
fitSummary    = summary(fit)
posterior     = as.array(fit)
list_of_draws = rstan::extract(loadedModel)
paramRoot     = as.name('interactionMat_vector_Agnostic')
numOfParams   = dim(list_of_draws[[paramRoot]])[2]
n_chains <- fit@sim$chains
n_warmup <- fit@sim$warmup2[1]
n_iter   <-fit@sim$iter[[1]]
print(c(n_iter,n_warmup,n_chains))
# paramNames=c()
# for(i in 1:numOfParams){
#   paramNames = c(paramNames,paste0(paramRoot,'[',i,']'))
# }
#
# color_scheme_set("brightblue")
# mcmc_dens(posterior, pars = paramNames,
#           facet_args = list(ncol = 1, strip.position = "left"))
#
# color_scheme_set("brightblue")
# mcmc_intervals(posterior, pars = paramNames)
#
# color_scheme_set("viridis")
# mcmc_trace(posterior, pars = paramNames,
#            facet_args = list(ncol = 1, strip.position = "left"))
#################################################
source("SETUP.R")
source('RESHAPE_DATA_KNIGHT_L6.R')
taxa_array = colnames(abundanceArray_meanSubjects)
abundanceArray_meanSubjects_use = abundanceArray_meanSubjects
abundanceArray_meanSubjects_use$day = rownames(abundanceArray_meanSubjects_use)
abundanceArray_meanSubjects_longer = abundanceArray_meanSubjects_use %>% pivot_longer(!day,names_to = 'taxa', values_to = 'abundance')
compartment_names = 'output_pred'
summaryTable = as.data.frame(summary(loadedModel,compartment_names)[[1]])
summaryTable$populationNames = rownames(summaryTable)
summaryTable$t    = sub(",.*","",sub(".*\\[", "", summaryTable$populationNames))  # Extract characters after pattern
summaryTable$taxa = sub("\\].*","",sub(".*,", "", summaryTable$populationNames))  # Extract characters after pattern
summaryTable_use = summaryTable[c('t','taxa','mean','2.5%','97.5%','50%')]
summaryTable_use$t = days_array[as.numeric(summaryTable_use$t)]
summaryTable_use$mean = as.numeric(summaryTable_use$mean)
summaryTable_use$`97.5%` = as.numeric(summaryTable_use$`97.5%`)
summaryTable_use$`2.5%` = as.numeric(summaryTable_use$`2.5%`)
summaryTable_use$`50%` = as.numeric(summaryTable_use$`50%`)
summaryTable_use$taxa = paste0('y_',summaryTable_use$taxa)
summaryTable_use = summaryTable_use %>% rowwise() %>% mutate(taxa = taxa_array[as.numeric(sub(",.*","",sub(".*\\_", "", taxa)))] )
abundanceArray_meanSubjects_longer$type ='stan'
out_longer$type='simulation'
out_longer_day0 = out_longer %>% filter(day==0)
graphics.off()
ggplot() +
geom_point(data=out_longer,aes(x=day,y=abundance,fill=taxa),shape=21,size=1,colour = "red", fill = "white") +
geom_ribbon(data=summaryTable_use,aes(x=t,ymin=`2.5%`,ymax=`97.5%`,fill=taxa),alpha=.5) +
geom_line(data=summaryTable_use,aes(x=t,y=`50%`),colour="black") +
facet_wrap(~ taxa ,scales="free",nrow=2) +
scale_colour_manual(values=c("grey20","grey")) +
scale_alpha_manual(values=c(1,0)) +
# scale_y_continuous(trans = 'log10')+
labs(x="sample index",y="abundance")
rm(list=ls())
setwd('/Users/burcutepekule/Library/CloudStorage/Dropbox/criticalwindow/code/R/RStan')
library("bayesplot")
library("ggplot2")
library("rstanarm")
library('rstan')
library('brms')
library('dplyr')
library(readxl)
library(writexl)
library(deSolve)
# https://cran.r-project.org/web/packages/rstan/vignettes/stanfit-objects.html
source("SETUP.R")
source('RESHAPE_DATA_KNIGHT_L6.R')
taxa_array = colnames(abundanceArray_meanSubjects)
abundanceArray_meanSubjects_use = abundanceArray_meanSubjects
abundanceArray_meanSubjects_use$day = rownames(abundanceArray_meanSubjects_use)
abundanceArray_meanSubjects_longer = abundanceArray_meanSubjects_use %>% pivot_longer(!day,names_to = 'taxa', values_to = 'abundance')
pathModelOutput='/Users/burcutepekule/Library/CloudStorage/Dropbox/criticalwindow/code/R/RStan/OUT/22062023/RDATA';
fileList   = list.files(path =pathModelOutput, pattern='.xlsx')
timestamps = unique(sub("\\.xlsx.*","",sub(".*\\_", "",fileList)))  # Extract characters after pattern
##### Pick the file
indexPick          = 1
timestampPick      = timestamps[indexPick]
growthRateVector   = read_excel(paste0(pathModelOutput,"/GROWTH_",timestampPick,".xlsx"))
interactionMatrix  = read_excel(paste0(pathModelOutput,"/INTERACTIONS_",timestampPick,".xlsx"))
numTaxa            = length(taxa_array)
t_end              = max(as.numeric(unique(abundanceArray_meanSubjects_longer$day)))
source("B1B_ODE_MODEL.R")
#################################################
### load the model object - clean up afterwards
fileNamePick = paste0(pathModelOutput,'/MODEL_SMOOTH_0_ODESOLVER_0_B1B_',timestampPick,'.RData')
temp.space <- new.env()
bar <- load(fileNamePick, temp.space)
loadedModel <- get(bar, temp.space)
rm(temp.space)
#################################################
fit           = loadedModel
fitSummary    = summary(fit)
posterior     = as.array(fit)
list_of_draws = rstan::extract(loadedModel)
paramRoot     = as.name('interactionMat_vector_Agnostic')
numOfParams   = dim(list_of_draws[[paramRoot]])[2]
n_chains <- fit@sim$chains
n_warmup <- fit@sim$warmup2[1]
n_iter   <-fit@sim$iter[[1]]
print(c(n_iter,n_warmup,n_chains))
# paramNames=c()
# for(i in 1:numOfParams){
#   paramNames = c(paramNames,paste0(paramRoot,'[',i,']'))
# }
#
# color_scheme_set("brightblue")
# mcmc_dens(posterior, pars = paramNames,
#           facet_args = list(ncol = 1, strip.position = "left"))
#
# color_scheme_set("brightblue")
# mcmc_intervals(posterior, pars = paramNames)
#
# color_scheme_set("viridis")
# mcmc_trace(posterior, pars = paramNames,
#            facet_args = list(ncol = 1, strip.position = "left"))
#################################################
source("SETUP.R")
source('RESHAPE_DATA_KNIGHT_L6.R')
taxa_array = colnames(abundanceArray_meanSubjects)
abundanceArray_meanSubjects_use = abundanceArray_meanSubjects
abundanceArray_meanSubjects_use$day = rownames(abundanceArray_meanSubjects_use)
abundanceArray_meanSubjects_longer = abundanceArray_meanSubjects_use %>% pivot_longer(!day,names_to = 'taxa', values_to = 'abundance')
compartment_names = 'output_pred'
summaryTable = as.data.frame(summary(loadedModel,compartment_names)[[1]])
summaryTable$populationNames = rownames(summaryTable)
summaryTable$t    = sub(",.*","",sub(".*\\[", "", summaryTable$populationNames))  # Extract characters after pattern
summaryTable$taxa = sub("\\].*","",sub(".*,", "", summaryTable$populationNames))  # Extract characters after pattern
summaryTable_use = summaryTable[c('t','taxa','mean','2.5%','97.5%','50%')]
summaryTable_use$t = days_array[as.numeric(summaryTable_use$t)]
summaryTable_use$mean = as.numeric(summaryTable_use$mean)
summaryTable_use$`97.5%` = as.numeric(summaryTable_use$`97.5%`)
summaryTable_use$`2.5%` = as.numeric(summaryTable_use$`2.5%`)
summaryTable_use$`50%` = as.numeric(summaryTable_use$`50%`)
summaryTable_use$taxa = paste0('y_',summaryTable_use$taxa)
summaryTable_use = summaryTable_use %>% rowwise() %>% mutate(taxa = taxa_array[as.numeric(sub(",.*","",sub(".*\\_", "", taxa)))] )
abundanceArray_meanSubjects_longer$type ='stan'
out_longer$type='simulation'
out_longer_day0 = out_longer %>% filter(day==0)
graphics.off()
ggplot() +
geom_point(data=out_longer,aes(x=day,y=abundance,fill=taxa),shape=21,size=1,colour = "red", fill = "white") +
geom_ribbon(data=summaryTable_use,aes(x=t,ymin=`2.5%`,ymax=`97.5%`,fill=taxa),alpha=.5) +
geom_line(data=summaryTable_use,aes(x=t,y=`50%`),colour="black") +
facet_wrap(~ taxa ,scales="free",nrow=2) +
scale_colour_manual(values=c("grey20","grey")) +
scale_alpha_manual(values=c(1,0)) +
# scale_y_continuous(trans = 'log10')+
labs(x="sample index",y="abundance")
View(out_longer)
View(out_longer)
graphics.off()
ggplot() +
geom_point(data=out_longer,aes(x=day,y=abundance,fill=taxa),shape=21,size=1,colour = "red", fill = "white")
source("B1B_ODE_MODEL.R")
graphics.off()
ggplot() +
geom_point(data=out_longer,aes(x=day,y=abundance,fill=taxa),shape=21,size=1,colour = "red", fill = "white") +
geom_ribbon(data=summaryTable_use,aes(x=t,ymin=`2.5%`,ymax=`97.5%`,fill=taxa),alpha=.5) +
geom_line(data=summaryTable_use,aes(x=t,y=`50%`),colour="black") +
facet_wrap(~ taxa ,scales="free",nrow=2) +
scale_colour_manual(values=c("grey20","grey")) +
scale_alpha_manual(values=c(1,0)) +
# scale_y_continuous(trans = 'log10')+
labs(x="sample index",y="abundance")
graphics.off()
ggplot() +
geom_point(data=out_longer,aes(x=day,y=abundance,fill=taxa),shape=21,size=1,colour = "red", fill = "white") +
geom_ribbon(data=summaryTable_use,aes(x=t,ymin=`2.5%`,ymax=`97.5%`,fill=taxa),alpha=.5) +
geom_line(data=summaryTable_use,aes(x=t,y=`50%`),colour="black") +
facet_wrap(~ taxa ,scales="free",nrow=2) +
scale_colour_manual(values=c("grey20","grey")) +
scale_alpha_manual(values=c(1,0)) +
# scale_y_continuous(trans = 'log10')+
labs(x="sample index",y="abundance")
y0_meanSubjects
#!/usr/bin/env Rscript
# args = commandArgs(trailingOnly=TRUE)
setwd('/Users/burcutepekule/Library/CloudStorage/Dropbox/criticalwindow/code/R/RStan')
source("SETUP.R")
source('RESHAPE_DATA_KNIGHT_L6.R')
# # test if there is at least one argument: if not, return an error
# if (length(args)==0) {
#   stop("At least one argument must be supplied (input file).n", call.=FALSE)
# } else if (length(args)>0) {
#   # default output file
#   df_config = read.table(args[1], header=TRUE)
# }
df_config     = read.table('config_raw_mid.txt', header = TRUE, sep = "", dec = ".")
scale         = df_config[which(df_config[,1]=='scale'),2]
smoothed      = df_config[which(df_config[,1]=='smoothed'),2]
numWarmup     = df_config[which(df_config[,1]=='numWarmup'),2]
numIterations = df_config[which(df_config[,1]=='numIterations'),2]
numChains     = df_config[which(df_config[,1]=='numChains'),2]
valSeed       = df_config[which(df_config[,1]=='valSeed'),2]
odeSolver     = df_config[which(df_config[,1]=='odeSolver'),2]
# numChains= 1 #debug
# HUMAN MICROBIOME PROJECT DATA
# y0_meanSubjects
# abundanceArray_meanSubjects
# data_knight_M5_t, day_grid_M5
# data_knight_F5_t, day_grid_F5
## scale up
# scale = 1E11 # TOO BIG
# scale = 0 # DOABLE
if(scale>0){
y0_meanSubjects             = round(scale*y0_meanSubjects)
names(y0_meanSubjects)      = colnames(abundanceArray_meanSubjects)
days_array = as.numeric(rownames(abundanceArray_meanSubjects))
taxa_array = colnames(abundanceArray_meanSubjects)
abundanceArray_meanSubjects = as.data.frame(lapply(abundanceArray_meanSubjects, function(x) as.numeric(x))) #normalize and scale to absolute abundance
abundanceArray_meanSubjects = as.data.frame(lapply(abundanceArray_meanSubjects, function(x) as.integer(round(scale*x)))) #normalize and scale to absolute abundance
abundanceArray_meanSubjects_longer$abundance = as.integer(round(scale*abundanceArray_meanSubjects_longer$abundance)) #normalize and scale to absolute abundance
phi_use_exp                 = max(round(log10(y0_meanSubjects)));
phi_use                     = 10^(phi_use_exp+0) # SEEMS LIKE 1E6 IS THE ONE THAT WORKS, SO NEED TO GET THIS FROM THE ORDER OF MAG. OF THE DATA
}else{
names(y0_meanSubjects)      = colnames(abundanceArray_meanSubjects)
days_array = as.numeric(rownames(abundanceArray_meanSubjects))
taxa_array = colnames(abundanceArray_meanSubjects)
abundanceArray_meanSubjects = as.data.frame(lapply(abundanceArray_meanSubjects, function(x) as.numeric(x))) #normalize and scale to absolute abundance
phi_use_exp                 = max((log10(y0_meanSubjects)));
phi_use                     = 10^(phi_use_exp+0) # SEEMS LIKE 1E6 IS THE ONE THAT WORKS, SO NEED TO GET THIS FROM THE ORDER OF MAG. OF THE DATA
}
indexes = 1:9 # ALL
abundanceArray_meanSubjects = abundanceArray_meanSubjects[,indexes]
y0_meanSubjects             = y0_meanSubjects[indexes]
taxa_array                  = taxa_array[indexes]
# maybe smooth before use?
if(smoothed==1){
abundanceArray_meanSubjects_keep = abundanceArray_meanSubjects
for (c in 1:dim(abundanceArray_meanSubjects)[2]){
tempcolumn  = abundanceArray_meanSubjects_keep[,c]
dayvector   = days_array
taxa_model  = loess(tempcolumn ~ days_array,  family = c("gaussian"), span=7)
smooth_data = predict(taxa_model, data.frame(day = days_array), se = TRUE)
# plot(smooth_data$fit)
abundanceArray_meanSubjects[,c]=unlist(smooth_data$fit)
}
}
data_list = list(
numTaxa          = length(taxa_array),
numTimeSteps     = length(days_array),
numAgnostic      = numAgnostic,
numGnostic       = numGnostic,
interactionMask_vector = interactionMask_vector,
y0               = y0_meanSubjects,
observations     = tibble(abundanceArray_meanSubjects),
# priors
p_mu           = c(0,4), # normal dist for growth parameters
p_a            = c(0,4), # normal dist for interaction parameters
p_phi          = 1/phi_use,
t0        = 0, #starting time
t_data    = days_array, #time bins of data
ts_pred   = days_array #time bins of prediction (not doing prediction currently)
)
if(scale>0){ # NEGATIVE BINOMIAL LIKELIHOOD
# RECOMPILE EACH TIME
if(file.exists("MODELS/MODEL_B1B_INT.rds")){
file.remove("MODELS/MODEL_B1B_INT.rds")
}
M_model  = stan_model("MODELS/MODEL_B1B_INT.stan")
T_model  = sampling(M_model,data = data_list,warmup=numWarmup,iter=numIterations,chains=numChains,seed=valSeed,init="random", refresh = 10)
}else{ # NORMAL LIKELIHOOD
# RECOMPILE EACH TIME
if(odeSolver==45){
if(file.exists("MODELS/MODEL_B1B_FLT_45.rds")){
file.remove("MODELS/MODEL_B1B_FLT_45.rds")
}
print('Picked ODE_45 model')
M_model  = stan_model("MODELS/MODEL_B1B_FLT_45.stan")
print('Compiled the model')
}else{
odeSolver = 0 #WILL GIVE THIS AS INPUT BUT STILL TO MAKE SURE IT IS A NUMBER FOR THE FILENAME
if(file.exists("MODELS/MODEL_B1B_FLT_BDF.rds")){
file.remove("MODELS/MODEL_B1B_FLT_BDF.rds")
}
print('Picked ODE_BDF model')
M_model  = stan_model("MODELS/MODEL_B1B_FLT_BDF.stan")
print('Compiled the model')
}
T_model  = sampling(M_model,data = data_list,warmup=numWarmup,iter=numIterations,chains=numChains,seed=valSeed,init="random", refresh = 10)
}
todaystr    = format(Sys.Date(), "%d%m%Y");
tstamp      = as.numeric(Sys.time());
direc2save  = paste0("OUT/",todaystr,"/RDATA")
mkdir(direc2save)
save(T_model, file = paste0(direc2save,"/MODEL_SMOOTH_",smoothed,"_ODESOLVER_",odeSolver,"_B1B_",round(tstamp),".RData"))
numAgnostic
numGnostic
(numTaxa+numAgnostic+numGnostic)
numTaxa+numTaxa*numTaxa
interactionMask_vector
length(interactionMask_vector)
#!/usr/bin/env Rscript
# args = commandArgs(trailingOnly=TRUE)
setwd('/Users/burcutepekule/Library/CloudStorage/Dropbox/criticalwindow/code/R/RStan')
source("SETUP.R")
source('RESHAPE_DATA_KNIGHT_L6.R')
# # test if there is at least one argument: if not, return an error
# if (length(args)==0) {
#   stop("At least one argument must be supplied (input file).n", call.=FALSE)
# } else if (length(args)>0) {
#   # default output file
#   df_config = read.table(args[1], header=TRUE)
# }
df_config     = read.table('config_raw_mid.txt', header = TRUE, sep = "", dec = ".")
scale         = df_config[which(df_config[,1]=='scale'),2]
smoothed      = df_config[which(df_config[,1]=='smoothed'),2]
numWarmup     = df_config[which(df_config[,1]=='numWarmup'),2]
numIterations = df_config[which(df_config[,1]=='numIterations'),2]
numChains     = df_config[which(df_config[,1]=='numChains'),2]
valSeed       = df_config[which(df_config[,1]=='valSeed'),2]
odeSolver     = df_config[which(df_config[,1]=='odeSolver'),2]
# numChains= 1 #debug
# HUMAN MICROBIOME PROJECT DATA
# y0_meanSubjects
# abundanceArray_meanSubjects
# data_knight_M5_t, day_grid_M5
# data_knight_F5_t, day_grid_F5
## scale up
# scale = 1E11 # TOO BIG
# scale = 0 # DOABLE
if(scale>0){
y0_meanSubjects             = round(scale*y0_meanSubjects)
names(y0_meanSubjects)      = colnames(abundanceArray_meanSubjects)
days_array = as.numeric(rownames(abundanceArray_meanSubjects))
taxa_array = colnames(abundanceArray_meanSubjects)
abundanceArray_meanSubjects = as.data.frame(lapply(abundanceArray_meanSubjects, function(x) as.numeric(x))) #normalize and scale to absolute abundance
abundanceArray_meanSubjects = as.data.frame(lapply(abundanceArray_meanSubjects, function(x) as.integer(round(scale*x)))) #normalize and scale to absolute abundance
abundanceArray_meanSubjects_longer$abundance = as.integer(round(scale*abundanceArray_meanSubjects_longer$abundance)) #normalize and scale to absolute abundance
phi_use_exp                 = max(round(log10(y0_meanSubjects)));
phi_use                     = 10^(phi_use_exp+0) # SEEMS LIKE 1E6 IS THE ONE THAT WORKS, SO NEED TO GET THIS FROM THE ORDER OF MAG. OF THE DATA
}else{
names(y0_meanSubjects)      = colnames(abundanceArray_meanSubjects)
days_array = as.numeric(rownames(abundanceArray_meanSubjects))
taxa_array = colnames(abundanceArray_meanSubjects)
abundanceArray_meanSubjects = as.data.frame(lapply(abundanceArray_meanSubjects, function(x) as.numeric(x))) #normalize and scale to absolute abundance
phi_use_exp                 = max((log10(y0_meanSubjects)));
phi_use                     = 10^(phi_use_exp+0) # SEEMS LIKE 1E6 IS THE ONE THAT WORKS, SO NEED TO GET THIS FROM THE ORDER OF MAG. OF THE DATA
}
indexes = 1:9 # ALL
abundanceArray_meanSubjects = abundanceArray_meanSubjects[,indexes]
y0_meanSubjects             = y0_meanSubjects[indexes]
taxa_array                  = taxa_array[indexes]
# maybe smooth before use?
if(smoothed==1){
abundanceArray_meanSubjects_keep = abundanceArray_meanSubjects
for (c in 1:dim(abundanceArray_meanSubjects)[2]){
tempcolumn  = abundanceArray_meanSubjects_keep[,c]
dayvector   = days_array
taxa_model  = loess(tempcolumn ~ days_array,  family = c("gaussian"), span=7)
smooth_data = predict(taxa_model, data.frame(day = days_array), se = TRUE)
# plot(smooth_data$fit)
abundanceArray_meanSubjects[,c]=unlist(smooth_data$fit)
}
}
data_list = list(
numTaxa          = length(taxa_array),
numTimeSteps     = length(days_array),
numAgnostic      = numAgnostic,
numGnostic       = numGnostic,
interactionMask_vector = interactionMask_vector,
y0               = y0_meanSubjects,
observations     = tibble(abundanceArray_meanSubjects),
# priors
p_mu           = c(0,4), # normal dist for growth parameters
p_a            = c(0,4), # normal dist for interaction parameters
p_phi          = 1/phi_use,
t0        = 0, #starting time
t_data    = days_array, #time bins of data
ts_pred   = days_array #time bins of prediction (not doing prediction currently)
)
if(scale>0){ # NEGATIVE BINOMIAL LIKELIHOOD
# RECOMPILE EACH TIME
if(file.exists("MODELS/MODEL_B1B_INT.rds")){
file.remove("MODELS/MODEL_B1B_INT.rds")
}
M_model  = stan_model("MODELS/MODEL_B1B_INT.stan")
T_model  = sampling(M_model,data = data_list,warmup=numWarmup,iter=numIterations,chains=numChains,seed=valSeed,init="random", refresh = 10)
}else{ # NORMAL LIKELIHOOD
# RECOMPILE EACH TIME
if(odeSolver==45){
if(file.exists("MODELS/MODEL_B1B_FLT_45.rds")){
file.remove("MODELS/MODEL_B1B_FLT_45.rds")
}
print('Picked ODE_45 model')
M_model  = stan_model("MODELS/MODEL_B1B_FLT_45.stan")
print('Compiled the model')
}else{
odeSolver = 0 #WILL GIVE THIS AS INPUT BUT STILL TO MAKE SURE IT IS A NUMBER FOR THE FILENAME
if(file.exists("MODELS/MODEL_B1B_FLT_BDF.rds")){
file.remove("MODELS/MODEL_B1B_FLT_BDF.rds")
}
print('Picked ODE_BDF model')
M_model  = stan_model("MODELS/MODEL_B1B_FLT_BDF.stan")
print('Compiled the model')
}
T_model  = sampling(M_model,data = data_list,warmup=numWarmup,iter=numIterations,chains=numChains,seed=valSeed,init="random", refresh = 10)
}
todaystr    = format(Sys.Date(), "%d%m%Y");
tstamp      = as.numeric(Sys.time());
direc2save  = paste0("OUT/",todaystr,"/RDATA")
mkdir(direc2save)
save(T_model, file = paste0(direc2save,"/MODEL_SMOOTH_",smoothed,"_ODESOLVER_",odeSolver,"_B1B_",round(tstamp),".RData"))
days_array
y0_meanSubjects
abundanceArray_meanSubjects
taxa_array
length((1+numTaxa):(numTaxa+numAgnostic))
length((numTaxa+numAgnostic+1):(numTaxa+numAgnostic+numGnostic))
numAgnostic
length((1+numTaxa):(numTaxa+numAgnostic))
